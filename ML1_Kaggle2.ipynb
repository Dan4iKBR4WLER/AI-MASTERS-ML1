{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d88b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees: 2011759, orcs: 47633\n",
      "нормализация\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2011759/2011759 [00:07<00:00, 281204.15it/s]\n",
      "100%|██████████| 47633/47633 [00:00<00:00, 69886.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поиск точных совпадений\n",
      "Точные совпадения: 10388\n",
      "Потенциально остается: Employees=2001371, orcs=37245\n",
      "Векторизация\n",
      "Поиск ближайших соседей (top 200)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [26:37<00:00, 66.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Левенштейн\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37245/37245 [02:15<00:00, 275.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего орков среди сотрудников надено: 13814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Даниил Дорожкин\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "employees = pd.read_parquet(\"employees.parquet\")\n",
    "orcs = pd.read_parquet(\"orcs.parquet\")\n",
    "print(f\"Employees: {len(employees)}, orcs: {len(orcs)}\")\n",
    "\n",
    "# приведение к привычному виду\n",
    "def normalize_fio(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    return str(s).lower().replace(\" \", \"\").replace(\".\", \"\").replace(\",\", \"\").replace(\"*\", \"\").replace(\"`\", \"\").replace(\"-\", \"\")\n",
    "#без устраненния очевидных опечаток tf iff работал хуже, а метрика левенштейна не меняется\n",
    "\n",
    "def normalize_date(d):\n",
    "    if pd.isna(d):\n",
    "        return \"\"\n",
    "    try:\n",
    "        return pd.to_datetime(d).strftime(\"%Y%m%d\")\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "print(\"нормализация\")\n",
    "for df in [employees, orcs]:\n",
    "    df[\"fio\"] = df.progress_apply(\n",
    "        lambda r: normalize_fio(r[\"surname\"]) +\n",
    "                  normalize_fio(r[\"name\"]) +\n",
    "                  normalize_fio(r[\"fathername\"]),\n",
    "        axis=1\n",
    "    )\n",
    "    df[\"norm_birth\"] = df[\"birthdate\"].apply(normalize_date)\n",
    "\n",
    "#точные совпадения по паспопт и инн, допускаем, что тут уже опеаток нет, по нескоьким проверкам с поискам сотрудника по орочьему паспорту \n",
    "#найдено аж 75%, значит опечаток действительно нет или их очень мало, на всякий случай\n",
    "#можно учесть в левенштейне, чтобы избежать пропусков со слегка отличающимися серией или номером\n",
    "\n",
    "#фамилии и имена содержали явные опечатки, явно не только в 25% данных\n",
    "print(\"Поиск точных совпадений\")\n",
    "strict_mask = (\n",
    "    employees[\"passport\"].isin(orcs[\"passport\"]) |\n",
    "    employees[\"inn\"].isin(orcs[\"inn\"])\n",
    ")\n",
    "strict_matches = employees[strict_mask].index.values\n",
    "print(f\"Точные совпадения: {len(strict_matches)}\")\n",
    "\n",
    "orc_candidates = orcs[\n",
    "    ~(orcs[\"passport\"].isin(employees[\"passport\"]) |\n",
    "      orcs[\"inn\"].isin(employees[\"inn\"]))\n",
    "].copy()\n",
    "\n",
    "emp_candidates = employees[~strict_mask].copy()\n",
    "\n",
    "print(f\"Потенциально остается: Employees={len(emp_candidates)}, orcs={len(orc_candidates)}\")\n",
    "\n",
    "#Векторизация\n",
    "\n",
    "# LSH / datasketch MinHash сильно хуже на коротких строках\n",
    "# splink сильно медленнее\n",
    "print(\"Векторизация\")\n",
    "vec = TfidfVectorizer(analyzer=\"char\", ngram_range=(2, 4)) #analyzer=\"char\" — устойчивость к опечаткам\n",
    "#ngram_range(2,4) — учитывает маленькие кусочки текста (би-три-квадро граммы)\n",
    "X_emp = vec.fit_transform(emp_candidates[\"fio\"] + emp_candidates[\"norm_birth\"])\n",
    "X_orc = vec.transform(orc_candidates[\"fio\"] + orc_candidates[\"norm_birth\"])\n",
    "\n",
    "# ---------- NN----------\n",
    "K = 200 #выбираем не одного, так как малое косинусное расстояние между векторами не гарантирует фактическое совпадение\n",
    "#строк, которые их задали, с большой вероятностью будет настоящий двойник из другого списка\n",
    "#без левенштейна будет много ложноположительных\n",
    "\n",
    "#это делитель 37245, чтобы не создавать громадную матрицу, вообще время работы программы отличаться не будет просто матрица расширится в бок\n",
    "#но вот потом на этапе проверки \n",
    "print(f\"Поиск ближайших соседей (top {K})...\")\n",
    "nn = NearestNeighbors(n_neighbors=K, metric=\"cosine\", n_jobs=-1)\n",
    "nn.fit(X_emp)\n",
    "\n",
    "batch_size = 1600 #TF IDF большой, ограничиваем нагрузку, тут параметры подлобраны на счет 0.9462, увеличивая батч и чсило соседей, добился 0.9576 \n",
    "#прога при этом работала 40 минут, но фильтрация по левенштейну затянулась\n",
    "#в тоерии можно сдеелать без разбиения на батчи и без ограничения по количеству соседей, но тогда фильтрация по левенштейну будет длиться более суток (проверено)\n",
    "orc_knn = []\n",
    "\n",
    "#X_emp — TF-IDF матрица сотрудников\n",
    "#X_orc — TF-IDF матрица орков\n",
    "\n",
    "#kneighbors находит топ-K ближайших\n",
    "#idx массив индексов сотрудников-кандидатов\n",
    "#Если batch = 3 орка и K=5, то матрица idx размером (3 × 5)\n",
    "#(batch_size × K)\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, X_orc.shape[0], batch_size)):\n",
    "    _, idx = nn.kneighbors(X_orc[i:i+batch_size]) #перебираем каждого орка батчами, возврааем матрицу ближайших сотрудников\n",
    "    orc_knn.extend([emp_candidates.index.values[ix] for ix in idx])\n",
    "    #emp_candidates.index.values[ix] — переводим индекс в оригинальный индекс таблицы сотрудников (до фильтра)\n",
    "\n",
    "orc_candidates[\"knn_idxs\"] = orc_knn\n",
    "#у каждого орка есть поле knn_idxs, содержащее по K ближайших сотрудников\n",
    "\n",
    "# Левенштейн\n",
    "print(\"Левенштейн\")\n",
    "selected = []\n",
    "\n",
    "for _, row in tqdm(orc_candidates.iterrows(), total=len(orc_candidates)):\n",
    "    best_score = 1.0\n",
    "    best_emp_idx = None\n",
    "\n",
    "    for emp_idx in row[\"knn_idxs\"]:\n",
    "        emp_row = employees.loc[emp_idx]\n",
    "\n",
    "        if emp_row[\"gender\"] != row[\"gender\"]:\n",
    "            continue\n",
    "\n",
    "        scores = [] #нормализованное расстояние, 0 - идеально, порог 0.25 допускаем для условного кирилл киллер в усреднении с датой и другими данными\n",
    "        scores.append(Levenshtein.normalized_distance(row[\"fio\"], emp_row[\"fio\"]))\n",
    "\n",
    "        if row[\"norm_birth\"] and emp_row[\"norm_birth\"]:\n",
    "            scores.append(Levenshtein.normalized_distance(row[\"norm_birth\"], emp_row[\"norm_birth\"]))\n",
    "\n",
    "#в целом это необязаительно, просто и так не объединяли в одну строку ФИО+ДР, но идею \"а вдруг\" объяснил \n",
    "        if pd.notna(row[\"passport\"]) and pd.notna(emp_row[\"passport\"]):\n",
    "            scores.append(Levenshtein.normalized_distance(str(row[\"passport\"]), str(emp_row[\"passport\"])))\n",
    "\n",
    "        if pd.notna(row[\"inn\"]) and pd.notna(emp_row[\"inn\"]):\n",
    "            scores.append(Levenshtein.normalized_distance(str(row[\"inn\"]), str(emp_row[\"inn\"])))\n",
    "\n",
    "        avg_score = np.mean(scores) #страховка от шумов и пропусков\n",
    "\n",
    "        if avg_score < best_score:\n",
    "            best_score = avg_score\n",
    "            best_emp_idx = emp_idx\n",
    "\n",
    "            #среди ближайших соседей считаем разные метрики и берем действительно максимально похожего best_emp_idx = emp_idx\n",
    "\n",
    "    if best_emp_idx is not None and best_score < 0.25: #покрывает две опечатки или перестановки в имени/ фамилии\n",
    "        #по наблюдениям, 0.3 - хуже, а промежуточные не пробовал \n",
    "        selected.append(best_emp_idx)\n",
    "\n",
    "selected = np.unique(np.array(selected, np.uint64))\n",
    "\n",
    "#объединяем новых и очевидных\n",
    "final_orcs = np.unique(np.concatenate([strict_matches, selected]))\n",
    "print(f\"Всего орков среди сотрудников надено: {len(final_orcs)}\")\n",
    "\n",
    "\n",
    "#сохраняем\n",
    "res = pd.DataFrame({\n",
    "    \"orig_index\": final_orcs.astype(np.uint64),\n",
    "}).reset_index(names=\"id\")\n",
    "\n",
    "res.to_parquet(\"submission.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e55b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
